{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHL - Predicting Wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "One of my previous portfolio pieces include an analysis of the NHL since 1964 to present. When I first undertook the piece I conducted the analysis using R, and it was done in my early days in data science. It has used both supervised and unsupervised machine learning methods for the predictive analytic portion.\n",
    "\n",
    "I am now redoing this piece, and this is just the first part of a multi faceted project that I am working on. It is my most favorite data to work with because of my love for hockey. Analytics have proven successful in other sports like baseball, however I have always believed that due to the \"bounce of the puck on a slippery surface\" it is VERY difficult to predict an outcome. That is my personal take on it, however, I want to prove this wrong and show that we are able to provide directionality thoroughout each part of this project. \n",
    "\n",
    "For this project I zeroed in from 1997 to present. This portion looks at predicting wins, so that I may be able to  help the number to give insight on the number of wins a team may finish with in a season. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willjdsouza\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import Lasso, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading data and visualizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(40)\n",
    "teams = pd.read_csv(\"C:/Users/willjdsouza/windows_stuff/Desktop/hockey_final.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Divison</th>\n",
       "      <th>Season</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>T</th>\n",
       "      <th>OT</th>\n",
       "      <th>P</th>\n",
       "      <th>ROW</th>\n",
       "      <th>...</th>\n",
       "      <th>GF/GP</th>\n",
       "      <th>GA/GP</th>\n",
       "      <th>PP%</th>\n",
       "      <th>PK%</th>\n",
       "      <th>S/GP</th>\n",
       "      <th>SA/GP</th>\n",
       "      <th>FOW%</th>\n",
       "      <th>W/GP</th>\n",
       "      <th>L/GP</th>\n",
       "      <th>P/GP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anaheim Ducks</td>\n",
       "      <td>PAC</td>\n",
       "      <td>1997</td>\n",
       "      <td>82</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.82</td>\n",
       "      <td>26.6</td>\n",
       "      <td>30.4</td>\n",
       "      <td>51.3</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arizona Coyotes</td>\n",
       "      <td>PAC</td>\n",
       "      <td>1997</td>\n",
       "      <td>82</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.84</td>\n",
       "      <td>27.7</td>\n",
       "      <td>27.1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boston Bruins</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1997</td>\n",
       "      <td>82</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.85</td>\n",
       "      <td>27.2</td>\n",
       "      <td>26.4</td>\n",
       "      <td>51.9</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buffalo Sabres</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1997</td>\n",
       "      <td>82</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.84</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.2</td>\n",
       "      <td>47.3</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>PAC</td>\n",
       "      <td>1997</td>\n",
       "      <td>82</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.84</td>\n",
       "      <td>27.7</td>\n",
       "      <td>27.8</td>\n",
       "      <td>46.9</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Team Divison  Season  GP   W   L   T  OT   P  ROW  ...   GF/GP  \\\n",
       "0    Anaheim Ducks     PAC    1997  82  26  43  13 NaN  65    0  ...    2.50   \n",
       "1  Arizona Coyotes     PAC    1997  82  35  35  12 NaN  82    0  ...    2.73   \n",
       "2    Boston Bruins     ATL    1997  82  39  30  13 NaN  91    0  ...    2.70   \n",
       "3   Buffalo Sabres     ATL    1997  82  36  29  17 NaN  89    0  ...    2.57   \n",
       "4   Calgary Flames     PAC    1997  82  26  41  15 NaN  67    0  ...    2.65   \n",
       "\n",
       "   GA/GP   PP%   PK%  S/GP  SA/GP  FOW%  W/GP  L/GP  P/GP  \n",
       "0   3.18  0.12  0.82  26.6   30.4  51.3  0.32  0.52  0.79  \n",
       "1   2.77  0.15  0.84  27.7   27.1  50.0  0.43  0.43  1.00  \n",
       "2   2.37  0.17  0.85  27.2   26.4  51.9  0.48  0.37  1.11  \n",
       "3   2.28  0.13  0.84  26.5   31.2  47.3  0.44  0.35  1.09  \n",
       "4   3.07  0.12  0.84  27.7   27.8  46.9  0.32  0.50  0.82  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>T</th>\n",
       "      <th>OT</th>\n",
       "      <th>P</th>\n",
       "      <th>ROW</th>\n",
       "      <th>P%</th>\n",
       "      <th>GF</th>\n",
       "      <th>...</th>\n",
       "      <th>GF/GP</th>\n",
       "      <th>GA/GP</th>\n",
       "      <th>PP%</th>\n",
       "      <th>PK%</th>\n",
       "      <th>S/GP</th>\n",
       "      <th>SA/GP</th>\n",
       "      <th>FOW%</th>\n",
       "      <th>W/GP</th>\n",
       "      <th>L/GP</th>\n",
       "      <th>P/GP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>539.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2007.309122</td>\n",
       "      <td>80.277027</td>\n",
       "      <td>38.278716</td>\n",
       "      <td>31.005068</td>\n",
       "      <td>3.719595</td>\n",
       "      <td>7.988868</td>\n",
       "      <td>87.550676</td>\n",
       "      <td>23.021959</td>\n",
       "      <td>0.546250</td>\n",
       "      <td>219.231419</td>\n",
       "      <td>...</td>\n",
       "      <td>2.729307</td>\n",
       "      <td>2.729291</td>\n",
       "      <td>0.176014</td>\n",
       "      <td>0.825186</td>\n",
       "      <td>29.288682</td>\n",
       "      <td>29.287500</td>\n",
       "      <td>49.990878</td>\n",
       "      <td>0.477230</td>\n",
       "      <td>0.386571</td>\n",
       "      <td>1.091199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.115420</td>\n",
       "      <td>7.463682</td>\n",
       "      <td>8.631682</td>\n",
       "      <td>7.850225</td>\n",
       "      <td>5.493182</td>\n",
       "      <td>3.561445</td>\n",
       "      <td>16.786732</td>\n",
       "      <td>17.827179</td>\n",
       "      <td>0.092118</td>\n",
       "      <td>32.931640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311560</td>\n",
       "      <td>0.343507</td>\n",
       "      <td>0.029611</td>\n",
       "      <td>0.029736</td>\n",
       "      <td>2.195702</td>\n",
       "      <td>2.482626</td>\n",
       "      <td>2.073061</td>\n",
       "      <td>0.099502</td>\n",
       "      <td>0.091092</td>\n",
       "      <td>0.184395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1997.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>1.890000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>44.100000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>204.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>2.480000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>48.600000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2008.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.715000</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>30.700000</td>\n",
       "      <td>30.900000</td>\n",
       "      <td>51.300000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>1.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>35.900000</td>\n",
       "      <td>56.400000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Season          GP           W           L           T  \\\n",
       "count   592.000000  592.000000  592.000000  592.000000  592.000000   \n",
       "mean   2007.309122   80.277027   38.278716   31.005068    3.719595   \n",
       "std       6.115420    7.463682    8.631682    7.850225    5.493182   \n",
       "min    1997.000000   48.000000   14.000000    7.000000    0.000000   \n",
       "25%    2002.000000   82.000000   32.000000   26.000000    0.000000   \n",
       "50%    2008.000000   82.000000   39.000000   30.000000    0.000000   \n",
       "75%    2013.000000   82.000000   45.000000   36.000000    9.000000   \n",
       "max    2017.000000   82.000000   58.000000   57.000000   20.000000   \n",
       "\n",
       "               OT           P         ROW          P%          GF     ...      \\\n",
       "count  539.000000  592.000000  592.000000  592.000000  592.000000     ...       \n",
       "mean     7.988868   87.550676   23.021959    0.546250  219.231419     ...       \n",
       "std      3.561445   16.786732   17.827179    0.092118   32.931640     ...       \n",
       "min      0.000000   36.000000    0.000000    0.240000  109.000000     ...       \n",
       "25%      5.000000   77.000000    0.000000    0.480000  204.750000     ...       \n",
       "50%      8.000000   90.500000   29.000000    0.560000  221.000000     ...       \n",
       "75%     11.000000  100.000000   38.000000    0.610000  241.000000     ...       \n",
       "max     18.000000  124.000000   54.000000    0.800000  313.000000     ...       \n",
       "\n",
       "            GF/GP       GA/GP         PP%         PK%        S/GP       SA/GP  \\\n",
       "count  592.000000  592.000000  592.000000  592.000000  592.000000  592.000000   \n",
       "mean     2.729307    2.729291    0.176014    0.825186   29.288682   29.287500   \n",
       "std      0.311560    0.343507    0.029611    0.029736    2.195702    2.482626   \n",
       "min      1.830000    1.890000    0.090000    0.730000   23.700000   22.100000   \n",
       "25%      2.520000    2.480000    0.160000    0.810000   27.800000   27.700000   \n",
       "50%      2.715000    2.710000    0.175000    0.830000   29.200000   29.400000   \n",
       "75%      2.940000    2.950000    0.190000    0.850000   30.700000   30.900000   \n",
       "max      3.820000    3.820000    0.270000    0.900000   36.200000   35.900000   \n",
       "\n",
       "             FOW%        W/GP        L/GP        P/GP  \n",
       "count  592.000000  592.000000  592.000000  592.000000  \n",
       "mean    49.990878    0.477230    0.386571    1.091199  \n",
       "std      2.073061    0.099502    0.091092    0.184395  \n",
       "min     44.100000    0.170000    0.150000    0.480000  \n",
       "25%     48.600000    0.410000    0.330000    0.960000  \n",
       "50%     50.000000    0.490000    0.375000    1.120000  \n",
       "75%     51.300000    0.550000    0.440000    1.220000  \n",
       "max     56.400000    0.750000    0.700000    1.600000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are are a number of ways I looked at the data, however I wanted to share a few visualizations I created with Kibana. I am becoming a huge fan of the elasticstack and am looking to work with it more. The visualizations are meant to be interactive, but I had to share static screenshots because it is quite difficult to share the interactive visualizations\n",
    "\n",
    "The first 4 charts I looked at the divisions as a whole and measured different metrics. The next 4 I looked at certain metrics given the teams in a division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Division.W_GP.PNG\">\n",
    "<img src=\"Division.L_GP.PNG\">\n",
    "<img src=\"Division.OTW.PNG\">\n",
    "<img src=\"Division.P_GP.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Team.MET.PNG\">\n",
    "<img src=\"Team.CEN.PNG\">\n",
    "<img src=\"Team.PAC.PNG\">\n",
    "<img src=\"Team.ATL.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The major point to share after looking at these visualizations can be summed up in one major point. The data is not only well distributed, it is also almost identical when comparing different groups. We dont see many spikes or outliers in the data which means that our predictions may come out quite well. \n",
    "\n",
    "When we segment the data, the magnitude of variances amongst the groups do not deviate from eachother greatly, so we can also that the leauge is highly competitive. Teams average out to having similar statistics, which points out how effective the salary cap system and talent is distributed amongst the teams in the leauge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Correlations & training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>T</th>\n",
       "      <th>OT</th>\n",
       "      <th>P</th>\n",
       "      <th>ROW</th>\n",
       "      <th>P%</th>\n",
       "      <th>GF</th>\n",
       "      <th>...</th>\n",
       "      <th>GF/GP</th>\n",
       "      <th>GA/GP</th>\n",
       "      <th>PP%</th>\n",
       "      <th>PK%</th>\n",
       "      <th>S/GP</th>\n",
       "      <th>SA/GP</th>\n",
       "      <th>FOW%</th>\n",
       "      <th>W/GP</th>\n",
       "      <th>L/GP</th>\n",
       "      <th>P/GP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177373</td>\n",
       "      <td>0.181012</td>\n",
       "      <td>-0.136116</td>\n",
       "      <td>-0.809865</td>\n",
       "      <td>0.505115</td>\n",
       "      <td>0.077867</td>\n",
       "      <td>0.789105</td>\n",
       "      <td>0.181496</td>\n",
       "      <td>-0.055463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065954</td>\n",
       "      <td>0.060104</td>\n",
       "      <td>0.386091</td>\n",
       "      <td>-0.401304</td>\n",
       "      <td>0.465158</td>\n",
       "      <td>0.411701</td>\n",
       "      <td>-0.001926</td>\n",
       "      <td>0.272418</td>\n",
       "      <td>-0.075458</td>\n",
       "      <td>0.184113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP</th>\n",
       "      <td>-0.177373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.382519</td>\n",
       "      <td>0.365407</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.176640</td>\n",
       "      <td>0.470428</td>\n",
       "      <td>0.029254</td>\n",
       "      <td>-0.026148</td>\n",
       "      <td>0.644819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>-0.051956</td>\n",
       "      <td>0.053287</td>\n",
       "      <td>0.016009</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.052917</td>\n",
       "      <td>-0.001935</td>\n",
       "      <td>-0.027757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>0.181012</td>\n",
       "      <td>0.382519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.616054</td>\n",
       "      <td>-0.233553</td>\n",
       "      <td>0.017296</td>\n",
       "      <td>0.972366</td>\n",
       "      <td>0.501531</td>\n",
       "      <td>0.882501</td>\n",
       "      <td>0.752254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679852</td>\n",
       "      <td>-0.557382</td>\n",
       "      <td>0.481532</td>\n",
       "      <td>0.271103</td>\n",
       "      <td>0.474018</td>\n",
       "      <td>-0.266050</td>\n",
       "      <td>0.244229</td>\n",
       "      <td>0.897587</td>\n",
       "      <td>-0.807669</td>\n",
       "      <td>0.882853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>-0.136116</td>\n",
       "      <td>0.365407</td>\n",
       "      <td>-0.616054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061754</td>\n",
       "      <td>0.064225</td>\n",
       "      <td>-0.621951</td>\n",
       "      <td>-0.243360</td>\n",
       "      <td>-0.904671</td>\n",
       "      <td>-0.235125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.591029</td>\n",
       "      <td>0.699828</td>\n",
       "      <td>-0.451655</td>\n",
       "      <td>-0.323976</td>\n",
       "      <td>-0.391293</td>\n",
       "      <td>0.398958</td>\n",
       "      <td>-0.276169</td>\n",
       "      <td>-0.832065</td>\n",
       "      <td>0.922180</td>\n",
       "      <td>-0.904485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>-0.809865</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>-0.233553</td>\n",
       "      <td>0.061754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.577276</td>\n",
       "      <td>-0.079354</td>\n",
       "      <td>-0.875922</td>\n",
       "      <td>-0.170142</td>\n",
       "      <td>-0.034324</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165546</td>\n",
       "      <td>-0.183196</td>\n",
       "      <td>-0.349126</td>\n",
       "      <td>0.354484</td>\n",
       "      <td>-0.442235</td>\n",
       "      <td>-0.414984</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>-0.317896</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>-0.174650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OT</th>\n",
       "      <td>0.505115</td>\n",
       "      <td>0.176640</td>\n",
       "      <td>0.017296</td>\n",
       "      <td>0.064225</td>\n",
       "      <td>-0.577276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061431</td>\n",
       "      <td>0.542787</td>\n",
       "      <td>-0.039366</td>\n",
       "      <td>0.085937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>0.155598</td>\n",
       "      <td>0.127578</td>\n",
       "      <td>-0.258787</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.334228</td>\n",
       "      <td>0.016708</td>\n",
       "      <td>-0.074660</td>\n",
       "      <td>-0.005045</td>\n",
       "      <td>-0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>0.077867</td>\n",
       "      <td>0.470428</td>\n",
       "      <td>0.972366</td>\n",
       "      <td>-0.621951</td>\n",
       "      <td>-0.079354</td>\n",
       "      <td>0.061431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384699</td>\n",
       "      <td>0.865218</td>\n",
       "      <td>0.783459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650600</td>\n",
       "      <td>-0.591539</td>\n",
       "      <td>0.435716</td>\n",
       "      <td>0.314598</td>\n",
       "      <td>0.433842</td>\n",
       "      <td>-0.317402</td>\n",
       "      <td>0.254774</td>\n",
       "      <td>0.827119</td>\n",
       "      <td>-0.847414</td>\n",
       "      <td>0.864596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROW</th>\n",
       "      <td>0.789105</td>\n",
       "      <td>0.029254</td>\n",
       "      <td>0.501531</td>\n",
       "      <td>-0.243360</td>\n",
       "      <td>-0.875922</td>\n",
       "      <td>0.542787</td>\n",
       "      <td>0.384699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.412881</td>\n",
       "      <td>0.283759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346541</td>\n",
       "      <td>-0.012981</td>\n",
       "      <td>0.454752</td>\n",
       "      <td>-0.248225</td>\n",
       "      <td>0.550003</td>\n",
       "      <td>0.312099</td>\n",
       "      <td>0.056723</td>\n",
       "      <td>0.522691</td>\n",
       "      <td>-0.275229</td>\n",
       "      <td>0.416673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P%</th>\n",
       "      <td>0.181496</td>\n",
       "      <td>-0.026148</td>\n",
       "      <td>0.882501</td>\n",
       "      <td>-0.904671</td>\n",
       "      <td>-0.170142</td>\n",
       "      <td>-0.039366</td>\n",
       "      <td>0.865218</td>\n",
       "      <td>0.412881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703547</td>\n",
       "      <td>-0.704378</td>\n",
       "      <td>0.519115</td>\n",
       "      <td>0.333571</td>\n",
       "      <td>0.479646</td>\n",
       "      <td>-0.371044</td>\n",
       "      <td>0.289894</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>-0.963586</td>\n",
       "      <td>0.999291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GF</th>\n",
       "      <td>-0.055463</td>\n",
       "      <td>0.644819</td>\n",
       "      <td>0.752254</td>\n",
       "      <td>-0.235125</td>\n",
       "      <td>-0.034324</td>\n",
       "      <td>0.085937</td>\n",
       "      <td>0.783459</td>\n",
       "      <td>0.283759</td>\n",
       "      <td>0.521767</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796320</td>\n",
       "      <td>-0.073855</td>\n",
       "      <td>0.403668</td>\n",
       "      <td>0.063637</td>\n",
       "      <td>0.397408</td>\n",
       "      <td>-0.083775</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.506965</td>\n",
       "      <td>-0.502532</td>\n",
       "      <td>0.520939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>-0.052496</td>\n",
       "      <td>0.610316</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>0.765047</td>\n",
       "      <td>-0.058860</td>\n",
       "      <td>0.227928</td>\n",
       "      <td>-0.202117</td>\n",
       "      <td>0.008901</td>\n",
       "      <td>-0.569100</td>\n",
       "      <td>0.308547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076600</td>\n",
       "      <td>0.817914</td>\n",
       "      <td>-0.155881</td>\n",
       "      <td>-0.458299</td>\n",
       "      <td>-0.088856</td>\n",
       "      <td>0.477067</td>\n",
       "      <td>-0.201573</td>\n",
       "      <td>-0.527428</td>\n",
       "      <td>0.575995</td>\n",
       "      <td>-0.568985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S/O W</th>\n",
       "      <td>0.557241</td>\n",
       "      <td>-0.002818</td>\n",
       "      <td>0.313496</td>\n",
       "      <td>-0.101977</td>\n",
       "      <td>-0.706535</td>\n",
       "      <td>0.376284</td>\n",
       "      <td>0.207635</td>\n",
       "      <td>0.685609</td>\n",
       "      <td>0.235791</td>\n",
       "      <td>0.072181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092506</td>\n",
       "      <td>0.042469</td>\n",
       "      <td>0.198212</td>\n",
       "      <td>-0.217578</td>\n",
       "      <td>0.336144</td>\n",
       "      <td>0.293349</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.338658</td>\n",
       "      <td>-0.116498</td>\n",
       "      <td>0.238372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GF/GP</th>\n",
       "      <td>0.065954</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.679852</td>\n",
       "      <td>-0.591029</td>\n",
       "      <td>-0.165546</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>0.650600</td>\n",
       "      <td>0.346541</td>\n",
       "      <td>0.703547</td>\n",
       "      <td>0.796320</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.136073</td>\n",
       "      <td>0.572100</td>\n",
       "      <td>0.043783</td>\n",
       "      <td>0.500127</td>\n",
       "      <td>-0.118393</td>\n",
       "      <td>0.154073</td>\n",
       "      <td>0.707110</td>\n",
       "      <td>-0.654206</td>\n",
       "      <td>0.703742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA/GP</th>\n",
       "      <td>0.060104</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>-0.557382</td>\n",
       "      <td>0.699828</td>\n",
       "      <td>-0.183196</td>\n",
       "      <td>0.155598</td>\n",
       "      <td>-0.591539</td>\n",
       "      <td>-0.012981</td>\n",
       "      <td>-0.704378</td>\n",
       "      <td>-0.073855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.155451</td>\n",
       "      <td>-0.620384</td>\n",
       "      <td>-0.127516</td>\n",
       "      <td>0.590837</td>\n",
       "      <td>-0.257291</td>\n",
       "      <td>-0.632093</td>\n",
       "      <td>0.733733</td>\n",
       "      <td>-0.703349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP%</th>\n",
       "      <td>0.386091</td>\n",
       "      <td>-0.051956</td>\n",
       "      <td>0.481532</td>\n",
       "      <td>-0.451655</td>\n",
       "      <td>-0.349126</td>\n",
       "      <td>0.127578</td>\n",
       "      <td>0.435716</td>\n",
       "      <td>0.454752</td>\n",
       "      <td>0.519115</td>\n",
       "      <td>0.403668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572100</td>\n",
       "      <td>-0.155451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.086593</td>\n",
       "      <td>0.403652</td>\n",
       "      <td>0.033225</td>\n",
       "      <td>0.154071</td>\n",
       "      <td>0.541475</td>\n",
       "      <td>-0.460064</td>\n",
       "      <td>0.519856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PK%</th>\n",
       "      <td>-0.401304</td>\n",
       "      <td>0.053287</td>\n",
       "      <td>0.271103</td>\n",
       "      <td>-0.323976</td>\n",
       "      <td>0.354484</td>\n",
       "      <td>-0.258787</td>\n",
       "      <td>0.314598</td>\n",
       "      <td>-0.248225</td>\n",
       "      <td>0.333571</td>\n",
       "      <td>0.063637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043783</td>\n",
       "      <td>-0.620384</td>\n",
       "      <td>-0.086593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.122560</td>\n",
       "      <td>-0.477878</td>\n",
       "      <td>0.150335</td>\n",
       "      <td>0.278047</td>\n",
       "      <td>-0.370788</td>\n",
       "      <td>0.332418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S/GP</th>\n",
       "      <td>0.465158</td>\n",
       "      <td>0.016009</td>\n",
       "      <td>0.474018</td>\n",
       "      <td>-0.391293</td>\n",
       "      <td>-0.442235</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.433842</td>\n",
       "      <td>0.550003</td>\n",
       "      <td>0.479646</td>\n",
       "      <td>0.397408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500127</td>\n",
       "      <td>-0.127516</td>\n",
       "      <td>0.403652</td>\n",
       "      <td>-0.122560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000352</td>\n",
       "      <td>0.277146</td>\n",
       "      <td>0.500540</td>\n",
       "      <td>-0.427186</td>\n",
       "      <td>0.479443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA/GP</th>\n",
       "      <td>0.411701</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>-0.266050</td>\n",
       "      <td>0.398958</td>\n",
       "      <td>-0.414984</td>\n",
       "      <td>0.334228</td>\n",
       "      <td>-0.317402</td>\n",
       "      <td>0.312099</td>\n",
       "      <td>-0.371044</td>\n",
       "      <td>-0.083775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118393</td>\n",
       "      <td>0.590837</td>\n",
       "      <td>0.033225</td>\n",
       "      <td>-0.477878</td>\n",
       "      <td>-0.000352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.274905</td>\n",
       "      <td>-0.296341</td>\n",
       "      <td>0.424890</td>\n",
       "      <td>-0.368631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOW%</th>\n",
       "      <td>-0.001926</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.244229</td>\n",
       "      <td>-0.276169</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.016708</td>\n",
       "      <td>0.254774</td>\n",
       "      <td>0.056723</td>\n",
       "      <td>0.289894</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154073</td>\n",
       "      <td>-0.257291</td>\n",
       "      <td>0.154071</td>\n",
       "      <td>0.150335</td>\n",
       "      <td>0.277146</td>\n",
       "      <td>-0.274905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.265685</td>\n",
       "      <td>-0.291070</td>\n",
       "      <td>0.289923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W/GP</th>\n",
       "      <td>0.272418</td>\n",
       "      <td>-0.052917</td>\n",
       "      <td>0.897587</td>\n",
       "      <td>-0.832065</td>\n",
       "      <td>-0.317896</td>\n",
       "      <td>-0.074660</td>\n",
       "      <td>0.827119</td>\n",
       "      <td>0.522691</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.506965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707110</td>\n",
       "      <td>-0.632093</td>\n",
       "      <td>0.541475</td>\n",
       "      <td>0.278047</td>\n",
       "      <td>0.500540</td>\n",
       "      <td>-0.296341</td>\n",
       "      <td>0.265685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.876011</td>\n",
       "      <td>0.971589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L/GP</th>\n",
       "      <td>-0.075458</td>\n",
       "      <td>-0.001935</td>\n",
       "      <td>-0.807669</td>\n",
       "      <td>0.922180</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>-0.005045</td>\n",
       "      <td>-0.847414</td>\n",
       "      <td>-0.275229</td>\n",
       "      <td>-0.963586</td>\n",
       "      <td>-0.502532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654206</td>\n",
       "      <td>0.733733</td>\n",
       "      <td>-0.460064</td>\n",
       "      <td>-0.370788</td>\n",
       "      <td>-0.427186</td>\n",
       "      <td>0.424890</td>\n",
       "      <td>-0.291070</td>\n",
       "      <td>-0.876011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.962893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P/GP</th>\n",
       "      <td>0.184113</td>\n",
       "      <td>-0.027757</td>\n",
       "      <td>0.882853</td>\n",
       "      <td>-0.904485</td>\n",
       "      <td>-0.174650</td>\n",
       "      <td>-0.037842</td>\n",
       "      <td>0.864596</td>\n",
       "      <td>0.416673</td>\n",
       "      <td>0.999291</td>\n",
       "      <td>0.520939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703742</td>\n",
       "      <td>-0.703349</td>\n",
       "      <td>0.519856</td>\n",
       "      <td>0.332418</td>\n",
       "      <td>0.479443</td>\n",
       "      <td>-0.368631</td>\n",
       "      <td>0.289923</td>\n",
       "      <td>0.971589</td>\n",
       "      <td>-0.962893</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Season        GP         W         L         T        OT         P  \\\n",
       "Season  1.000000 -0.177373  0.181012 -0.136116 -0.809865  0.505115  0.077867   \n",
       "GP     -0.177373  1.000000  0.382519  0.365407  0.156578  0.176640  0.470428   \n",
       "W       0.181012  0.382519  1.000000 -0.616054 -0.233553  0.017296  0.972366   \n",
       "L      -0.136116  0.365407 -0.616054  1.000000  0.061754  0.064225 -0.621951   \n",
       "T      -0.809865  0.156578 -0.233553  0.061754  1.000000 -0.577276 -0.079354   \n",
       "OT      0.505115  0.176640  0.017296  0.064225 -0.577276  1.000000  0.061431   \n",
       "P       0.077867  0.470428  0.972366 -0.621951 -0.079354  0.061431  1.000000   \n",
       "ROW     0.789105  0.029254  0.501531 -0.243360 -0.875922  0.542787  0.384699   \n",
       "P%      0.181496 -0.026148  0.882501 -0.904671 -0.170142 -0.039366  0.865218   \n",
       "GF     -0.055463  0.644819  0.752254 -0.235125 -0.034324  0.085937  0.783459   \n",
       "GA     -0.052496  0.610316 -0.225019  0.765047 -0.058860  0.227928 -0.202117   \n",
       "S/O W   0.557241 -0.002818  0.313496 -0.101977 -0.706535  0.376284  0.207635   \n",
       "GF/GP   0.065954  0.055398  0.679852 -0.591029 -0.165546 -0.037446  0.650600   \n",
       "GA/GP   0.060104  0.050234 -0.557382  0.699828 -0.183196  0.155598 -0.591539   \n",
       "PP%     0.386091 -0.051956  0.481532 -0.451655 -0.349126  0.127578  0.435716   \n",
       "PK%    -0.401304  0.053287  0.271103 -0.323976  0.354484 -0.258787  0.314598   \n",
       "S/GP    0.465158  0.016009  0.474018 -0.391293 -0.442235  0.305755  0.433842   \n",
       "SA/GP   0.411701  0.013428 -0.266050  0.398958 -0.414984  0.334228 -0.317402   \n",
       "FOW%   -0.001926  0.000098  0.244229 -0.276169  0.001751  0.016708  0.254774   \n",
       "W/GP    0.272418 -0.052917  0.897587 -0.832065 -0.317896 -0.074660  0.827119   \n",
       "L/GP   -0.075458 -0.001935 -0.807669  0.922180  0.005886 -0.005045 -0.847414   \n",
       "P/GP    0.184113 -0.027757  0.882853 -0.904485 -0.174650 -0.037842  0.864596   \n",
       "\n",
       "             ROW        P%        GF    ...        GF/GP     GA/GP       PP%  \\\n",
       "Season  0.789105  0.181496 -0.055463    ...     0.065954  0.060104  0.386091   \n",
       "GP      0.029254 -0.026148  0.644819    ...     0.055398  0.050234 -0.051956   \n",
       "W       0.501531  0.882501  0.752254    ...     0.679852 -0.557382  0.481532   \n",
       "L      -0.243360 -0.904671 -0.235125    ...    -0.591029  0.699828 -0.451655   \n",
       "T      -0.875922 -0.170142 -0.034324    ...    -0.165546 -0.183196 -0.349126   \n",
       "OT      0.542787 -0.039366  0.085937    ...    -0.037446  0.155598  0.127578   \n",
       "P       0.384699  0.865218  0.783459    ...     0.650600 -0.591539  0.435716   \n",
       "ROW     1.000000  0.412881  0.283759    ...     0.346541 -0.012981  0.454752   \n",
       "P%      0.412881  1.000000  0.521767    ...     0.703547 -0.704378  0.519115   \n",
       "GF      0.283759  0.521767  1.000000    ...     0.796320 -0.073855  0.403668   \n",
       "GA      0.008901 -0.569100  0.308547    ...    -0.076600  0.817914 -0.155881   \n",
       "S/O W   0.685609  0.235791  0.072181    ...     0.092506  0.042469  0.198212   \n",
       "GF/GP   0.346541  0.703547  0.796320    ...     1.000000 -0.136073  0.572100   \n",
       "GA/GP  -0.012981 -0.704378 -0.073855    ...    -0.136073  1.000000 -0.155451   \n",
       "PP%     0.454752  0.519115  0.403668    ...     0.572100 -0.155451  1.000000   \n",
       "PK%    -0.248225  0.333571  0.063637    ...     0.043783 -0.620384 -0.086593   \n",
       "S/GP    0.550003  0.479646  0.397408    ...     0.500127 -0.127516  0.403652   \n",
       "SA/GP   0.312099 -0.371044 -0.083775    ...    -0.118393  0.590837  0.033225   \n",
       "FOW%    0.056723  0.289894  0.118000    ...     0.154073 -0.257291  0.154071   \n",
       "W/GP    0.522691  0.970370  0.506965    ...     0.707110 -0.632093  0.541475   \n",
       "L/GP   -0.275229 -0.963586 -0.502532    ...    -0.654206  0.733733 -0.460064   \n",
       "P/GP    0.416673  0.999291  0.520939    ...     0.703742 -0.703349  0.519856   \n",
       "\n",
       "             PK%      S/GP     SA/GP      FOW%      W/GP      L/GP      P/GP  \n",
       "Season -0.401304  0.465158  0.411701 -0.001926  0.272418 -0.075458  0.184113  \n",
       "GP      0.053287  0.016009  0.013428  0.000098 -0.052917 -0.001935 -0.027757  \n",
       "W       0.271103  0.474018 -0.266050  0.244229  0.897587 -0.807669  0.882853  \n",
       "L      -0.323976 -0.391293  0.398958 -0.276169 -0.832065  0.922180 -0.904485  \n",
       "T       0.354484 -0.442235 -0.414984  0.001751 -0.317896  0.005886 -0.174650  \n",
       "OT     -0.258787  0.305755  0.334228  0.016708 -0.074660 -0.005045 -0.037842  \n",
       "P       0.314598  0.433842 -0.317402  0.254774  0.827119 -0.847414  0.864596  \n",
       "ROW    -0.248225  0.550003  0.312099  0.056723  0.522691 -0.275229  0.416673  \n",
       "P%      0.333571  0.479646 -0.371044  0.289894  0.970370 -0.963586  0.999291  \n",
       "GF      0.063637  0.397408 -0.083775  0.118000  0.506965 -0.502532  0.520939  \n",
       "GA     -0.458299 -0.088856  0.477067 -0.201573 -0.527428  0.575995 -0.568985  \n",
       "S/O W  -0.217578  0.336144  0.293349  0.009885  0.338658 -0.116498  0.238372  \n",
       "GF/GP   0.043783  0.500127 -0.118393  0.154073  0.707110 -0.654206  0.703742  \n",
       "GA/GP  -0.620384 -0.127516  0.590837 -0.257291 -0.632093  0.733733 -0.703349  \n",
       "PP%    -0.086593  0.403652  0.033225  0.154071  0.541475 -0.460064  0.519856  \n",
       "PK%     1.000000 -0.122560 -0.477878  0.150335  0.278047 -0.370788  0.332418  \n",
       "S/GP   -0.122560  1.000000 -0.000352  0.277146  0.500540 -0.427186  0.479443  \n",
       "SA/GP  -0.477878 -0.000352  1.000000 -0.274905 -0.296341  0.424890 -0.368631  \n",
       "FOW%    0.150335  0.277146 -0.274905  1.000000  0.265685 -0.291070  0.289923  \n",
       "W/GP    0.278047  0.500540 -0.296341  0.265685  1.000000 -0.876011  0.971589  \n",
       "L/GP   -0.370788 -0.427186  0.424890 -0.291070 -0.876011  1.000000 -0.962893  \n",
       "P/GP    0.332418  0.479443 -0.368631  0.289923  0.971589 -0.962893  1.000000  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train length: 503\n",
      "X_test length: 89\n",
      "y_train length: 503\n",
      "y_test length: 89\n"
     ]
    }
   ],
   "source": [
    "X = teams[['GF/GP', 'GA/GP', 'PP%', 'PK%', 'S/GP']] #features for training\n",
    "y = teams.loc[:, ['W']] #target variable\n",
    "\n",
    "X_train_prepared, X_test_prepared, y_train, y_test,  = train_test_split(X, y, test_size=0.15, random_state=42) #random split for train and test sets\n",
    "\n",
    "print(\"X_train length:\", len(X_train_prepared))\n",
    "print(\"X_test length:\", len(X_test_prepared))\n",
    "print(\"y_train length:\", len(y_train))\n",
    "print(\"y_test length:\", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GF         int64\n",
       "GF/GP    float64\n",
       "GA/GP    float64\n",
       "PP%      float64\n",
       "PK%      float64\n",
       "S/GP     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prepared.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Building a full pipeline for data transformation\n",
    "\n",
    "#numerical_values = list(teams[['GF', 'GF/GP', 'GA/GP', 'PP%', 'PK%', 'S/GP']])\n",
    "\n",
    "#catergorical_values = teams[['Team', 'Divison']]\n",
    "\n",
    "#num_pipeline = Pipeline([\n",
    "  #      ('selector', DataFrameSelector(numerical_values)),\n",
    " #       ('std_scaler', StandardScaler()), #scaling data using a standard scaler\n",
    "#    ])\n",
    "\n",
    "#cat_pipeline = Pipeline([\n",
    "#        ('selector', DataFrameSelector(catergorical_values)),\n",
    "#        ('cat_encoder', OneHotEncoder(sparse=)),\n",
    "#    ]) \n",
    "\n",
    "\n",
    "#full_pipeline = FeatureUnion(transformer_list=[\n",
    "#        (\"num_pipeline\", num_pipeline),\n",
    "#        (\"cat_pipeline\", cat_pipeline),\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "#X_train_prepared = full_pipeline.fit_transform(X_train) \n",
    "#X_test_prepared = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shortlisting models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willjdsouza\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\willjdsouza\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\willjdsouza\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\willjdsouza\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Scores - R2 Score: 0.8378634286978851 RMSE: 3.2372092753413644\n",
      "Lasso Scores - RMSE: 4.473793839362244\n",
      "SGD Scores - RMSE: 3.2372092753413644\n",
      "Decision Tree Scores - RMSE: 0.0\n",
      "Random Forest Scores - RMSE: 1.6037295003020817\n",
      "Adaboost (Random Forest) Scores - RMSE: 1.015701776804382\n",
      "Adaboost (Decision Trees) Scores - RMSE: 0.16076358548345154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willjdsouza\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "lin_r = LinearRegression()\n",
    "lin_r.fit(X_train_prepared, y_train)\n",
    "lin_r_predict = lin_r.predict(X_train_prepared)\n",
    "lin_r_scores = mean_squared_error(lin_r_predict, np.ravel(y_train))\n",
    "\n",
    "\n",
    "\n",
    "las = Lasso()\n",
    "las.fit(X_train_prepared, y_train)\n",
    "las_predict = las.predict(X_train_prepared)\n",
    "las_scores = mean_squared_error(las_predict, np.ravel(y_train))\n",
    "\n",
    "\n",
    "sgd = SGDRegressor()\n",
    "sgd.fit(X_train_prepared, y_train)\n",
    "sgd_predict = sgd.predict(X_train_prepared)\n",
    "sgd_scores = mean_squared_error(sgd_predict, np.ravel(y_train))\n",
    "\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(X_train_prepared, y_train)\n",
    "dtr_predict = dtr.predict(X_train_prepared)\n",
    "dtr_scores = mean_squared_error(dtr_predict, np.ravel(y_train))\n",
    "\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train_prepared, y_train)\n",
    "rfr_predict = rfr.predict(X_train_prepared)\n",
    "rfr_scores = mean_squared_error(rfr_predict, np.ravel(y_train))\n",
    "\n",
    "\n",
    "ada_rfr = AdaBoostRegressor(rfr)\n",
    "ada_rfr.fit(X_train_prepared, y_train)\n",
    "ada_rfr_predict = ada_rfr.predict(X_train_prepared)\n",
    "ada_rfr_scores = mean_squared_error(ada_rfr_predict, np.ravel(y_train))\n",
    "\n",
    "\n",
    "ada_dtr = AdaBoostRegressor(dtr)\n",
    "ada_dtr.fit(X_train_prepared, y_train)\n",
    "ada_dtr_predict = ada_dtr.predict(X_train_prepared)\n",
    "ada_dtr_scores = mean_squared_error(ada_dtr_predict, np.ravel(y_train))\n",
    "\n",
    "print(\"Linear Regression Scores - R2 Score:\", r2_score(lin_r_predict, np.ravel(y_train)), \"RMSE:\", \n",
    "      np.sqrt(lin_r_scores))\n",
    "\n",
    "print(\"Lasso Scores - RMSE:\", np.sqrt(las_scores))\n",
    "      \n",
    "print(\"SGD Scores - RMSE:\", np.sqrt(lin_r_scores))\n",
    "\n",
    "print(\"Decision Tree Scores - RMSE:\", np.sqrt(dtr_scores))\n",
    "\n",
    "print(\"Random Forest Scores - RMSE:\", np.sqrt(rfr_scores))\n",
    "\n",
    "print(\"Adaboost (Random Forest) Scores - RMSE:\", np.sqrt(ada_rfr_scores))\n",
    "\n",
    "print(\"Adaboost (Decision Trees) Scores - RMSE:\", np.sqrt(ada_dtr_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "During the shortlisting phase, it looks like all models do fairly well. The decision trees fit the data tremendously well, however, I can easily tell that this will cause overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Hypertuning random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 12}\n",
      "3.6572469973649473\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "    {'n_estimators': [8, 10, 12,],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf':[1, 3, 5]}\n",
    "  ]\n",
    "\n",
    "rfrc = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rfr, param_grid,\n",
    "scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_prepared, np.ravel(y_train))\n",
    "print(grid_search.best_params_)\n",
    "print(np.sqrt(-grid_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After many attempts at hypertuning, it was difficult to find any sort of gain with it. Turns out the default paramaeters itself work out nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set and comaprisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I compared the variancse between 4 regressors (random forest, decision tree, linear regression and adaboost). I wanted to see which regressor generalized well so I could choose the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Training Scores</th>\n",
       "      <th>Testing Scores</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>3.237209</td>\n",
       "      <td>3.911993</td>\n",
       "      <td>0.674783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Trees</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.576838</td>\n",
       "      <td>5.576838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adaboost (Decision Trees)</td>\n",
       "      <td>0.160764</td>\n",
       "      <td>4.488437</td>\n",
       "      <td>4.327673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.603730</td>\n",
       "      <td>4.346198</td>\n",
       "      <td>2.742469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost (Random Forest)</td>\n",
       "      <td>1.015702</td>\n",
       "      <td>4.182508</td>\n",
       "      <td>3.166806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Method  Training Scores  Testing Scores  Variance\n",
       "0          Linear Regression         3.237209        3.911993  0.674783\n",
       "1             Decision Trees         0.000000        5.576838  5.576838\n",
       "2  Adaboost (Decision Trees)         0.160764        4.488437  4.327673\n",
       "3              Random Forest         1.603730        4.346198  2.742469\n",
       "4   Adaboost (Random Forest)         1.015702        4.182508  3.166806"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_predict = rfr.predict(X_test_prepared)\n",
    "rfr_test_scores = mean_squared_error(rfr_predict, np.ravel(y_test))\n",
    "\n",
    "dtr_predict= dtr.predict(X_test_prepared)\n",
    "dtr_test_scores = mean_squared_error(dtr_predict, np.ravel(y_test))\n",
    "    \n",
    "lin_r_predict = lin_r.predict(X_test_prepared)\n",
    "lin_r_test_scores = mean_squared_error(lin_r_predict, y_test)\n",
    "    \n",
    "ada_dtr_predict = ada_dtr.predict(X_test_prepared)\n",
    "ada_dtr_test_scores = mean_squared_error(ada_dtr_predict, np.ravel(y_test))\n",
    "    \n",
    "ada_rfr_predict = ada_rfr.predict(X_test_prepared)\n",
    "ada_rfr_test_scores = mean_squared_error(ada_rfr_predict, np.ravel(y_test))\n",
    "    \n",
    "d = pd.DataFrame({'Method': ['Linear Regression', 'Decision Trees', 'Adaboost (Decision Trees)',\n",
    "                             'Random Forest', 'Adaboost (Random Forest)'], \n",
    "                  'Training Scores': [np.sqrt(lin_r_scores), np.sqrt(dtr_scores), np.sqrt(ada_dtr_scores), \n",
    "                                      np.sqrt(rfr_scores), np.sqrt(ada_rfr_scores)], \n",
    "                  'Testing Scores' : [np.sqrt(lin_r_test_scores), np.sqrt(dtr_test_scores), \n",
    "                                      np.sqrt(ada_dtr_test_scores), np.sqrt(rfr_test_scores), \n",
    "                                      np.sqrt(ada_rfr_test_scores)]\n",
    "                 })\n",
    "    \n",
    "d['Variance'] = d['Testing Scores'] - d['Training Scores']\n",
    "\n",
    "d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In my opinion, it seems like Linear Regression or Random Forest is the way to go. Not only did they score the highest in the test set but the variance between the models training and testing set was minimal. If using a randomized search, it may be possible to find parameters that best fit the random forest model and be able to better score than the linear regression.\n",
    "\n",
    "\n",
    "For my next part of this project I will be looking more closely on the player level, and will either use TensorFlow or Keras for the machine learning portion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('hockey_model.pkl', 'wb') as file:\n",
    "    pickle.dump(lin_r, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
